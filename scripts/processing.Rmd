---
title: "processing CHIPs data to get satellite imagery for the locations"
author: "Xiaowei Wang"
output: github_document
---


```{r}

library(haven)
# yourData = read_dta("CHIP2013_rural_household_f_income_asset.dta")
# yourData

# yourData2 = read_dta("RHS_w2_vill.dta")
# yourData3 = read_dta("RHS_w2_abc.dta")
# yourData4 = read_dta("RHS_w2_d.dta")
# yourData5 = read_dta("RHS_w2_e.dta")


# yourData2
# yourData3
# yourData4
# yourData5
```



```{r}
library(tidyverse)
# 2174 is CHIPS from 2002 
# for some reason this one has the clearest county level data
main_table_chips_2002 <- read_tsv('data/2002/DS0006/21741-0006-Data.tsv')
main_table_chips_1995 <- read_tsv('data/1995/DS0002/03012-0002-Data.tsv')
main_table_chips_1988 <- read_dta('data/1988/09836-0002-Data.dta')
main_table_chips_2008 <- read_dta("data/2008/RHS_w2_vill.dta")
main_table_chips_2013 <- read_dta("data/2013/CHIP2013_rural_household_f_income_asset.dta")


```

```{r}
#main_table_chips_2013$coun
setdiff(main_table_chips_1995$A1, main_table_chips_2002$coun)
#unique(main_table_chips_1995$A1)
#unique(main_table_chips_2002$coun)

ababa <- c(main_table_chips_2013$coun,main_table_chips_1995$A1,main_table_chips_2002$coun )
unique(ababa)
```

```{r}
# main_table_chips is a tale with 84 columns and 37969 rows
# the first column is county (coun), second column is vill (village), hous (is house)
```

# Get administrative divisions of China
```{r}
library(dplyr)

counties_main <- read_csv('https://raw.githubusercontent.com/modood/Administrative-divisions-of-China/master/dist/areas.csv')

counties_main
```

```{r}

#add long lat columns to the counties data

counties_main$lat <- 'NA'
counties_main$long <- 'NA'

city_main <- read_csv('../Administrative-divisions-of-China/dist/cities.csv')
province_main <- read_csv('../Administrative-divisions-of-China/dist/provinces.csv')

prov_county_main <- left_join(counties_main, province_main,
                              by=c('provinceCode'='code'))

prov_county_main <- prov_county_main %>%
    rename('cityName' = name.y, 
           'countyName' = name.x) %>%
    mutate(., geocodeAdd = paste0(cityName,countyName))


prov_county_main



```


```{r}

pcoun_codes_1 <- filter(prov_county_main, code < 400000)
pcoun_codes_2 <- filter(prov_county_main, code >= 400000)
```


#Grabbing the long lats from google maps

Example request:

##Geocoding
https://maps.googleapis.com/maps/api/geocode/json?address=1600+Amphitheatre+Parkway,+Mountain+View,+CA&key=YOUR_API_KEY

https://maps.googleapis.com/maps/api/geocode/json?address=辽宁省凤城市&key=AIzaSyAE8v4YljHZYZJ03VydAtAn5yNOGIfr50g 

##Static Map

https://maps.googleapis.com/maps/api/staticmap?center=40.452297,124.066919&zoom=16&size=400x400&maptype=satellite&key=AIzaSyDW8FM0kdCTFMF5iRO3z_tjWynVuzp8_iw

```{r}

# prov_county_main has the city and county data.
# concatenate the cityName and the countyName to feed in the address to google maps geocode api 

library(jsonlite)
library(httr)
library(ggmap)


```

```{r}

ggmap_credentials()

register_google(key='')

ggmap_credentials()

library(ggmap)

ggmap_credentials()


```

```{r}


infile <- 'pcoun_2'
data <-pcoun_codes_2

addresses = data$geocodeAdd

#define a function that will process googles server responses for us.
getGeoDetails <- function(address){   
   #use the gecode function to query google servers
   geo_reply = geocode(address, output='all', messaging=TRUE, override_limit=TRUE)
   #now extract the bits that we need from the returned list

   answer <- data.frame(lat=NA, long=NA, accuracy=NA, formatted_address=NA, address_type=NA, status=NA)
   answer$status <- geo_reply$status
 
   #if we are over the query limit - want to pause for an hour
   while(geo_reply$status == "OVER_QUERY_LIMIT"){
       print("OVER QUERY LIMIT - Pausing for 1 hour at:") 
       time <- Sys.time()
       print(as.character(time))
       Sys.sleep(60*60)
       geo_reply = geocode(address, output='all', messaging=TRUE, override_limit=TRUE)
       answer$status <- geo_reply$status
   }
 
   #return Na's if we didn't get a match:
   if (geo_reply$status != "OK"){
       return(answer)
   }   
   #else, extract what we need from the Google server reply into a dataframe:
   answer$lat <- geo_reply$results[[1]]$geometry$location$lat
   answer$long <- geo_reply$results[[1]]$geometry$location$lng   
   if (length(geo_reply$results[[1]]$types) > 0){
       answer$accuracy <- geo_reply$results[[1]]$types[[1]]
   }
   answer$address_type <- paste(geo_reply$results[[1]]$types, collapse=',')
   answer$formatted_address <- geo_reply$results[[1]]$formatted_address
    
   return(answer)
}
 
#initialise a dataframe to hold the results
geocoded <- data.frame()
# find out where to start in the address list (if the script was interrupted before):
startindex <- 1
#if a temp file exists - load it up and count the rows!
tempfilename <- paste0(infile, '_temp_geocoded.rds')
if (file.exists(tempfilename)){
       print("Found temp file - resuming from index:")
       geocoded <- readRDS(tempfilename)
       startindex <- nrow(geocoded)+1
       print(startindex)
}
 
# Start the geocoding process - address by address. geocode() function takes care of query speed limit.
for (ii in seq(startindex, length(addresses))){
   print(paste("Working on index", ii, "of", length(addresses)))
   #query the google geocoder - this will pause here if we are over the limit.
    
   result = getGeoDetails(addresses[ii]) 
   print(result$status)     
   result$index <- ii
   #append the answer to the results file.
   geocoded <- rbind(geocoded, result)
   #save temporary results as we are going along
   saveRDS(geocoded, tempfilename)
}

```

```{r}
blar <- data.frame(matrix(ncol = 3, nrow = 1516))
#now we add the latitude and longitude to the main data

blar$status <- geocoded$status
blar$formatted_address <- geocoded$formatted_address
blar$index <- geocoded$index
blar$lat <- geocoded$lat
blar$long <- geocoded$long
blar$accuracy <- geocoded$accuracy
 


#finally write it all to the output files
#saveRDS(data, paste0("../data/", infile ,"_geocoded.rds"))
write.table(blar, file=paste0("", infile ,"_geocoded.csv"), sep=",", row.names=FALSE)

```

# Now there's two tables, put them together vertically

```{r}
a <- read_csv('pcoun_1_geocoded.csv')
b <- read_csv('pcoun_2_geocoded.csv')
geocoded_areas <- bind_rows(a,b)

prov_county_main$lat <- geocoded_areas$lat
prov_county_main$long <- geocoded_areas$long

prov_county_main$engAdd <- geocoded_areas$formatted_address
prov_county_main
```

```{r}

```

```{r}
# villages_main <- read_csv('../Administrative-divisions-of-China/dist/villages.csv')
# villages_main
# villages_main this is the list of villages, not necessarily helpful, wait for response from the chinese village researchers
```

```{r}

n <- left_join(main_table_chips_2002, prov_county_main, by=c('coun'='code'))


```


```{r}

n

```


```{r}
library(ggplot2)
library(ggmap)
#  test out the get map based on long lat
location <- get_map(location = c(lon = 116.4164, lat = 39.92835), zoom = 16, maptype = "satellite") 

location 


df<-data.frame(116.4164,39.92835)
      #a+ggplot(df) # Not sure what you intend here
ggmap(location, extent ="device")+
  geom_point(data=df,aes(x=116.4164,y=39.92835))

ggsave('aaaaaaa', device='tiff')

```


## Make bounding box off of 
```{r}
bounding_box <- function(lat, lon, dist, in.miles = TRUE) {

    ## Helper functions
    if (in.miles) {
        ang_rad <- function(miles) miles/3958.756
    } else {
        ang_rad <- function(miles) miles/1000
    }
    `%+/-%` <- function(x, margin){x + c(-1, +1)*margin}
    deg2rad <- function(x) x/(180/pi)
    rad2deg <- function(x) x*(180/pi)
    lat_range <- function(latr, r) rad2deg(latr %+/-% r)
    lon_range <- function(lonr, dlon) rad2deg(lonr %+/-% dlon)

    r <- ang_rad(dist)
    latr <- deg2rad(lat)
    lonr <- deg2rad(lon)
    dlon <- asin(sin(r)/cos(latr))

    m <- matrix(c(lon_range(lonr = lonr, dlon = dlon), 
        lat_range(latr=latr, r=r)), nrow=2, byrow = TRUE)

    dimnames(m) <- list(c("lng", "lat"), c("min", "max"))
    m
}

```